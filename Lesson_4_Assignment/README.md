This Assignment includes extract corpus from wiki Chinese, and word2vec. The main packages used are 
hanziconv(traditional chinese to simplified Chinese), jieba (word cutting for Chinese), gensim(word2vec) and following visualization.

I make two folders, one for smaller txt file extracted(wiki02), another one for all txt files(mega big).Feel free 
to view these scripts. For all_text, I just upload py file since my jupyter notebook cannot handle so large txt file,
but script should work well on Pycharm.
